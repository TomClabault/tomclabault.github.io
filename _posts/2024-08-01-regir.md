---
layout: distill
title: ReGIR - An advanced implementation for many-lights offline rendering
date: 2025-08-17 14:45:00+0200
description: 
tags: path-tracing
thumbnail: assets/img/blogs/regir/thumbnail.jpg
categories: hiprt-path-tracer
related_posts: false
related_publications: true
toc:
  sidebar: left
  
bibliography: blogs/regir-many-lights.bib
---





<!-- Scripts for the ImageBox -->
<link rel="stylesheet" href="/assets/css/distill-width-override.css">
<link rel="stylesheet" href="/assets/css/ImageBox/ImageBox.css">
<script src="/assets/js/ImageBox/ImageBox.js"></script>
<script src="/assets/blogs-assets/ReGIR-Many-Lights/ImageBox/data.js"></script>
<!-- Scripts for the ImageBox -->











# The many-lights sampling problem
## Resampled Importance Sampling

# The many-lights sampling problem

To render a 3D scene, a naive "brute-force" path tracer sends out rays from the camera, bounce the rays around the scene multiple
times and hopes fingers crossed that the ray is eventually going to hit a light. In the event that the ray leaves the scene without having
hit a light, the pixel stays black and you've done the work for nothing. On top of that if the lights of your scene are very small or very far
away (or more generally, are small in solid angle at your shading point), then naively bouncing rays around is going to have a very low
probability to actually hit a light source.

The solution to that in practice, rather than hoping that the rays are going to hit a light, is to purposefully choose a light from all the lights
that exist in your scene, shoot a shadow ray towards that light to see if it is occluded, and if it's not, use that light to shade the current vertex
along your path. This method is called next-event estimation (NEE).

However, it isn't that simple. The subtle question is: how do I choose the light that I shoot a shadow ray to? Do we just choose the light completely at random?
That works, but from an efficiency standpoint, this is far from ideal, especially when there are tons of lights in the scene: 
- I want to choose a light for my point X on a surface
- There are 1000 lights in the scene
- Only 1 light meaningfully illuminates my point X, all the other 999 lights are too far away and don't contribute much at all to X

If I choose the lights for NEE completely at random, there's a 1/1000 chance that I'm going to choose the good light for the point X. That's not amazing and
this is going to cause very high variance (i.e. very high levels of noise) in our image and our render is going to take a while to converge to a clean image.

<div class="col-sm mt-3 mt-md-0">
		{% include figure.liquid path="assets/img/blogs/ReGIR-Many-Lights/twr-uniform-1SPP-vs-ref.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
</div>
<div class="caption">
	Top: one sample per pixel, choosing lights completely at random for NEE.
	Bottom: reference, converged image.
</div>

Surely this is going to take a while to converge.

> ##### Note
>
> Unless stated otherwise, all images in this blog post are rendered with 0 bounces (shoot a camera ray, find the first hit, do next-event estimation and you're done). 
> This is to focus on the variance of our NEE estimator. Adding more bounces would introduce the variance of path sampling and it would be harder to
> evaluate whether we're going in the right direction or not with regards to reducing the variance of our NEE estimator.
{: .block-tip }

Brief detour to the mathematics of why we have so much noise when choosing lights uniformly at random.

Ultimately, when estimating direct lighting using next-event estimation, we're trying to solve the following integral at each point $P$ in our scene:

\begin{equation}
L_o(P, \omega_o) = \int_{A}^{}f(P, \omega_o, \omega_i)L_e(x)V(P\leftrightarrow x)cos(\theta)dA_x
\label{directLightingIntegral}
\end{equation}

With:
- $L_o(P, \omega_o)$ the reflected radiance of point $P$ in direction $\omega_o$ (which can be the direction to the camera for example)
- $\int_{A}$ is the integral over the surface of our lights in the scene: to estimate the radiance that our point $P$ receives from the lights of the scene, we need a way of taking into account
all the lights of the scene. One way of doing that is to take all the lights and then consider all the points on the surface of these lights.
"Considering all the points of the surfaces of all the lights" is what we're doing here when integrating over $A$. $A$ can then be thought of as the union of
the area of all the lights and we're taking a point $dA_x$ on this union of areas.
- $f(P, \omega_o, \omega_i)$ is the BSDF used to evaluate the reflected radiance at point $P$ in direction $\omega_o$ of the light coming from direction $\omega_i$ (which is $x - P$).
- $L_e(x)$ is the emission intensity of the point $x$
- $V(P\leftrightarrow x)$ is the visibility term that evaluates whether our point $P$ can see the point $x$ on the surface of a light or not (is it occluded by some geometry in the scene).
- $cos(\theta)$ is the attenuation term
- $x$ is a point on the surface of a light source

## Resampled Importance Sampling

## substitle

citation test<d-cite key="jefferyHierarchicalAdaptiveSampling"></d-cite>

	- We won't be introducing RIS, plenty of resources to do the job better than me
	- ReGIR basics: RIS per grid cell per reservoir. RIS again at shading time
- Improving ReGIR
	- Representative cell data --> get closer to the integrand with cosine terms and everything
	- Spatial reuse
	- Integration with NEE++
	- Hash grid with surface normals
	- Hash grid with wavy cells to avoid aliasing
	- BRDF resampling at primary hits
		- Better product sampling options out there
		- Doesn't work at secondary hits
- Avoiding bias
	- With cosine terms and everything in the grid fill target function, we now have an issue because some lights may be rejected -> need canonical samples
		- We need good MIS weights so that canonical sample don't add too much noise
	- Bias on perfect mirror surfaces: we need BSDF samples MIS at shading time
		- MIS: New multi-pairwise MIS for shading
- Correlations
	- More reservoirs per cell
	- Using reservoirs of past frames to improve the effective reservoir count at frame N
		- Doesn't work when accumulating because we now have temporal correlations in between frames
- Improving performance
	- Light presampling
	- Less reservoirs at later bounces
- Improving base sampling
	- Cache cells
	- Variance issue when we have a ton of lights contributing to the same cell but our alias table can only contain so many lights so the rest has to be sample with a fallback sampling technique which adds a ton of noise
- A note on adapting that to real-time

